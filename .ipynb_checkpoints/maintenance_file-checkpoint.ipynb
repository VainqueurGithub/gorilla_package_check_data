{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593d7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define package and module names\n",
    "package_name = \"gorilla_package_check_data\"\n",
    "os.makedirs(package_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18741769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gorilla_package_check_data/check_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gorilla_package_check_data/check_data.py\n",
    "import csv\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#source_raw = \"C:/Users/vainq/CheckandUpload_Gorilla_data/data/raw_data/monitoring\"# data source where csv file containing gorilla monitoring raw data is stored\n",
    "#source_checked = \"C:/Users/vainq/CheckandUpload_Gorilla_data/data/checked_data/monitoring\"# data source where csv file containing gorilla monitoring checked data is stored\n",
    "#database=\"dianfossey\"\n",
    "#user='vainqueur'\n",
    "#password='123'\n",
    "#host='127.0.0.1'\n",
    "#port= '5432'\n",
    "#database= 'dianfossey\n",
    "\n",
    "def create_engine(database,user,password,host,port):\n",
    "    try:\n",
    "        # Attempt to connect to the database\n",
    "        engine = create_engine('postgresql+psycopg2://'+user+':'+password+'@'+host+':'+port+'/'+database)\n",
    "        return engine\n",
    "    except OperationalError as e:\n",
    "        # Handle connection failure\n",
    "        if \"password authentication failed\" in str(e):\n",
    "            print(f\"OperationalError: Password authentication failed for user '{user}'.\")\n",
    "            print(\"Please check your username and password.\")\n",
    "        else:\n",
    "            print(\"OperationalError:\", e)\n",
    "\n",
    "        # Optional: retry logic or prompt for a new password here\n",
    "        return None\n",
    "\n",
    "def connect_to_db(database,user,password,host,port):\n",
    "    try:\n",
    "        # Attempt to connect to the database\n",
    "        connection = psycopg2.connect(\n",
    "            dbname=database,\n",
    "            user=user\n",
    "            password=password,  # Replace this with the actual password\n",
    "            host=host,\n",
    "            port=port\n",
    "        )\n",
    "        print(\"Connection successful!\")\n",
    "        return connection\n",
    "    except OperationalError as e:\n",
    "        # Handle connection failure\n",
    "        if \"password authentication failed\" in str(e):\n",
    "            print(f\"OperationalError: Password authentication failed for user '{user}'.\")\n",
    "            print(\"Please check your username and password.\")\n",
    "        else:\n",
    "            print(\"OperationalError:\", e)\n",
    "\n",
    "        # Optional: retry logic or prompt for a new password here\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_csv(source_raw):\n",
    "    # Open the file and read the first line to detect the delimiter\n",
    "    with open(source_raw+'/data_fail_surveillance.csv', \"r\") as csvfile:\n",
    "        # Read the file's content\n",
    "        sample = csvfile.readline()\n",
    "        \n",
    "        # Use Sniffer to detect the delimiter\n",
    "        dialect = csv.Sniffer().sniff(sample)\n",
    "        delimiter = dialect.delimiter\n",
    "    \n",
    "    # Read the data to pandas dataframe by assigning the correct delimiter\n",
    "\n",
    "    if delimiter==',':\n",
    "        data = pd.read_csv(source_raw+'/data_fail_surveillance.csv', sep = ',', encoding = 'latin1')\n",
    "    elif delimiter==';':\n",
    "        data = pd.read_csv(source_raw+'/data_fail_surveillance.csv', sep = ';', encoding = 'latin1')\n",
    "    return data\n",
    "\n",
    "def raw_monitoring_data_checking(data):\n",
    "    \n",
    "    ''' This function check the validity of data from csv file. Most importantly the date format and nombre column'''\n",
    "\n",
    "    # Formating date_surveillance column to '%d/%m/%Y' format\n",
    "    try:\n",
    "        # Try parsing with the first format\n",
    "        data['date_surveillance'] = pd.to_datetime(data.date_surveillance)\n",
    "        print(\"date parsed succeffully\")\n",
    "    except ValueError:\n",
    "        # Provide a helpful message and suggest the correct format\n",
    "        print(f\"Make sure date_surveillance '{data['date_surveillance']}' column is parsed to this format '%d/%m/%Y'.\")\n",
    "    \n",
    "        \n",
    "    #Cleaning nombre column     \n",
    "        \n",
    "    try:\n",
    "        # Try to convert the value directly to an integer\n",
    "        data['nombre'] = data['nombre'].fillna(0) # Assign 0 to all nan value in this column\n",
    "        data['nombre'] = data['nombre'].astype(int) # Convert this column to int \n",
    "        data['nombre'] = data['nombre'].astype(str) # Convert this column to string\n",
    "        print(\"nombre Converted succeffully\")\n",
    "    except ValueError:\n",
    "        print(f\"Make sure '{data['nombre']}'is numeric characters.\")\n",
    "    \n",
    "    return data\n",
    "        \n",
    "def retrieve_data_psql(database,user,password,host,port):\n",
    "    \n",
    "    '''This function connect python to psql and retrieve data from psql'''\n",
    "    #establishing the connection\n",
    "\n",
    "    conn = connect_to_db(database=database, user=user, password=password, host=host, port=port)\n",
    "    #Setting auto commit false\n",
    "    conn.autocommit = True\n",
    "    #Creating a cursor object using the cursor() method\n",
    "    cursor_espece = conn.cursor()\n",
    "    cursor_signe = conn.cursor()\n",
    "    cursor_equipe = conn.cursor()\n",
    "    cursor_nombre = conn.cursor()\n",
    "    cursor_age = conn.cursor()\n",
    "    cursor_chef_equipe = conn.cursor()\n",
    "    \n",
    "    #Retrieving data\n",
    "    cursor_espece.execute('''SELECT nom_espece from prog_gorille.espece''')\n",
    "    cursor_signe.execute('''SELECT valeur from prog_gorille.signes''')\n",
    "    cursor_equipe.execute('''SELECT nom_equipe from prog_gorille.equipe_surveillance''')\n",
    "    cursor_nombre.execute('''SELECT valeur from prog_gorille.nombre''')\n",
    "    cursor_age.execute('''SELECT valeur from prog_gorille.age''')\n",
    "    cursor_chef_equipe.execute('''SELECT num_pisteur from prog_gorille.pisteur''')\n",
    "    \n",
    "    #Fetching rows from the table\n",
    "    especes = cursor_espece.fetchall();\n",
    "    signes = cursor_signe.fetchall();\n",
    "    equipes = cursor_equipe.fetchall();\n",
    "    nombres = cursor_nombre.fetchall();\n",
    "    ages = cursor_age.fetchall();\n",
    "    chef_equipes = cursor_chef_equipe.fetchall();\n",
    "    \n",
    "    #Commit your changes in the database\n",
    "    conn.commit()\n",
    "    #Closing the connection\n",
    "    conn.close()\n",
    "    \n",
    "    #Creating single dataframe for each cursor, and add nan value if neccessary\n",
    "    df_espece = pd.DataFrame(especes, columns=['espece'])\n",
    "    df_signe = pd.DataFrame(signes, columns=['signe'])\n",
    "    df_signe2 = pd.DataFrame([[np.nan]], columns=['signe'])\n",
    "    df_signe = pd.concat([df_signe,df_signe2], ignore_index=True)\n",
    "\n",
    "    df_nombre = pd.DataFrame(nombres, columns=['nombre'])\n",
    "    df_nombre2 = pd.DataFrame([[np.nan]], columns=['nombre'])\n",
    "    df_nombre = pd.concat([df_nombre,df_nombre2], ignore_index=True)\n",
    "\n",
    "    df_equipe = pd.DataFrame(equipes, columns=['equipe'])\n",
    "    df_age = pd.DataFrame(ages, columns=['age'])\n",
    "    df_age2 = pd.DataFrame([[np.nan]], columns=['age'])\n",
    "    df_age = pd.concat([df_age,df_age2], ignore_index=True)\n",
    "\n",
    "    df_chef_equipe = pd.DataFrame(chef_equipes, columns=['chef_equipe'])\n",
    "    \n",
    "    return df_espece, df_signe, df_nombre, df_equipe, df_age, df_chef_equipe\n",
    "    #except OperationalError:\n",
    "        #return print(\"Check Psql connection parameters, it seems some parameters are incorect\")\n",
    "\n",
    "\n",
    "def checking_data_integrity(source_raw,source_checked,df_espece, df_signe, df_nombre, df_equipe, df_age, df_chef_equipe,data):\n",
    "    ''' This function check data integrity before downloading the data into psql.'''\n",
    "    \n",
    "    data_success = data.loc[(data['observation'].isin(df_espece['espece'])) & (data['signe'].isin(df_signe['signe'])) &\n",
    "        (data['equipe'].isin(df_equipe['equipe'])) & (data['age_jours'].isin(df_age['age'])) & \n",
    "         (data['chef_equipe'].isin(df_chef_equipe['chef_equipe'])) &\n",
    "         (data['nombre'].isin(df_nombre['nombre']))]\n",
    "    data_success\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_fail = data.loc[(~data['observation'].isin(df_espece['espece'])) | (~data['signe'].isin(df_signe['signe'])) |\n",
    "        (~data['equipe'].isin(df_equipe['equipe'])) | (~data['age_jours'].isin(df_age['age'])) | \n",
    "         (~data['chef_equipe'].isin(df_chef_equipe['chef_equipe'])) | (~data['nombre'].isin(df_nombre['nombre']))]\n",
    "\n",
    "    \n",
    "    # Check if the data_success_surveillance CSV file exists\n",
    "    if os.path.exists(source_checked+'/data_success_surveillance.csv'):\n",
    "                      # Read the existing CSV file\n",
    "                      existing_df = pd.read_csv(source_checked+'/data_success_surveillance.csv')\n",
    "                      # Merge the new DataFrame with the existing DataFrame\n",
    "                      combined_df = pd.concat([existing_df, data_success], ignore_index=True)\n",
    "    else:\n",
    "        # If the file does not exist, use the new DataFrame as the combined DataFrame\n",
    "        combined_df = data_success\n",
    "\n",
    "    \n",
    "    try:\n",
    "        data_fail.to_csv(source_raw+'/data_fail_surveillance.csv', index=False)\n",
    "        # Write the combined DataFrame back to the CSV file\n",
    "        combined_df.to_csv(source_checked+'/data_success_surveillance.csv', index=False)\n",
    "        \n",
    "        if len(data_fail)==0:\n",
    "            print('ALL YOUR DATA IS VALIDATED, READY TO BE INTEGRETED INTO PSQL')\n",
    "        \n",
    "        else:\n",
    "            print(f\"YOU STILL HAVE SOME DATA TO VALIDATE, '{len(data_fail)}' raw seem to have issues check your data_fail_surveillance.csv file.\")\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(\"The script fail to write data on the file, make sure both data_fail_surveillance and data_success_surveillance csv files are not opened\")\n",
    "    \n",
    "            \n",
    "    #return message\n",
    "    \n",
    "\n",
    "def data_downloading_psql(source_checked, user,password,host,port,database):\n",
    "    \n",
    "    try:\n",
    "        engine = create_engine('postgresql+psycopg2://'+user+':'+password+'@'+host+':'+port+'/'+database)\n",
    "        try:\n",
    "            data_success = pd.read_csv(source_checked+'/data_success_surveillance.csv', encoding = 'latin1')\n",
    "            data_success.to_sql('surveillance', engine, schema='prog_gorille',if_exists='append', index=False)\n",
    "        except PermissionError:\n",
    "            print(\"The script fail to write data on the file, make sure both data_fail_surveillance and data_success_surveillance csv files are not opened\")\n",
    "    except OperationalError:\n",
    "        print(\"Check Psql connection parameters, it seems some parameters are incorect\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75ef340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gorilla_package_check_data/import_data_into_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gorilla_package_check_data/import_data_into_db.py\n",
    "\n",
    "def another_function():\n",
    "    return \"Hello from module 2!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bb999c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gorilla_package_check_data/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gorilla_package_check_data/__init__.py\n",
    "\n",
    "from .check_data import raw_monitoring_data_checking,data_base_connection,checking_data_integrity,data_downloading_psql,read_csv\n",
    "from .import_data_into_db import another_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4577817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gorilla_package_check_data/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gorilla_package_check_data/setup.py\n",
    "\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name=\"gorilla_package_check_data\",\n",
    "    version=\"0.1\",\n",
    "    packages=find_packages(),\n",
    "    install_requires=[],  # Add any dependencies if required\n",
    "    author=\"Vainqueur KILINDO BULAMBO\",\n",
    "    author_email=\"vbulambo@gorillafund.org\",\n",
    "    description=\"This package check gorilla tracking and monitoring data before to store them in Psql database\",\n",
    "    long_description=\"This package check gorilla tracking and monitoring data before to store them in Psql database\",\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    url=\"https://github.com/VainqueurGithub/gorilla_package_check_data.git\",\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires='>=3.6',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fd0b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/vainq/CheckandUpload_Gorilla_data\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: gorilla-package-check-data\n",
      "  Attempting uninstall: gorilla-package-check-data\n",
      "    Found existing installation: gorilla-package-check-data 0.1\n",
      "    Uninstalling gorilla-package-check-data-0.1:\n",
      "      Successfully uninstalled gorilla-package-check-data-0.1\n",
      "  Running setup.py develop for gorilla-package-check-data\n",
      "Successfully installed gorilla-package-check-data-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorilla_package_check_data import raw_monitoring_data_checking, data_base_connection,read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3d126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
