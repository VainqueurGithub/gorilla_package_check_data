{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7b0b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/vainq/CheckandUpload_Gorilla_data\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: gorilla-package-check-data\n",
      "  Attempting uninstall: gorilla-package-check-data\n",
      "    Found existing installation: gorilla-package-check-data 0.1\n",
      "    Uninstalling gorilla-package-check-data-0.1:\n",
      "      Successfully uninstalled gorilla-package-check-data-0.1\n",
      "  Running setup.py develop for gorilla-package-check-data\n",
      "Successfully installed gorilla-package-check-data-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Run this command to instal the package locally\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4ef434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gorilla_package_check_data import raw_tracking_data_checking,tr_checking_data_integrity,tr_data_downloading_psql,tr_read_csv,tr_create_engine,tr_connect_to_db,tr_retrieve_data_psql\n",
    "import csv\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "source_raw = \"C:/Users/vainq/CheckandUpload_Gorilla_data/data/raw_data/tracking\"# data source where csv file containing gorilla monitoring raw data is stored\n",
    "source_checked = \"C:/Users/vainq/CheckandUpload_Gorilla_data/data/checked_data/tracking\"# data source where csv file containing gorilla monitoring checked data is stored\n",
    "\n",
    "user='vainqueur'\n",
    "password='123'\n",
    "host='127.0.0.1'\n",
    "port= '5432'\n",
    "database= 'dianfossey'\n",
    "\n",
    "# Open the file and read the first line to detect the delimiter\n",
    "\n",
    "try:\n",
    "    with open(source_raw+'/data_fail_pistage.csv', \"r\") as csvfile:\n",
    "        # Read the file's content\n",
    "        sample = csvfile.readline()\n",
    "    \n",
    "        # Use Sniffer to detect the delimiter\n",
    "        dialect = csv.Sniffer().sniff(sample)\n",
    "        delimiter = dialect.delimiter\n",
    "\n",
    "    # Read the data to pandas dataframe by assigning the correct delimiter\n",
    "\n",
    "    if delimiter==',':\n",
    "        data = pd.read_csv(source_raw+'/data_fail_pistage.csv', sep = ',', encoding = 'latin1')\n",
    "    elif delimiter==';':\n",
    "        data = pd.read_csv(source_raw+'/data_fail_pistage.csv', sep = ';', encoding = 'latin1')\n",
    "except FileNotFoundError:\n",
    "    print(\"Directory or file non fund, check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cfcaea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date parsed succeffully\n",
      "nombre Converted succeffully\n"
     ]
    }
   ],
   "source": [
    "# Run this code to check any typo or wrong format in date_surveillance and nombre column \n",
    "try:\n",
    "    data =raw_tracking_data_checking(data)\n",
    "    #Run this code if you want to display the checked dataframe\n",
    "    #data\n",
    "except NameError:\n",
    "    print(\"It seems your dataframe has not been created yet. process above scripts first to create your dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c2dcd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "df_espece, df_signe, df_nombre, df_foret, df_age, df_chef_equipe, df_type, df_partie_consomme, df_famille_gorille = tr_retrieve_data_psql(database,user,password,host,port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60868e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL YOUR DATA IS VALIDATED, READY TO BE INTEGRETED INTO PSQL\n"
     ]
    }
   ],
   "source": [
    "#Run this code to load your data into psql\n",
    "try:\n",
    "    tr_checking_data_integrity(source_raw,source_checked,df_espece,df_signe,df_nombre,df_foret,df_age,df_chef_equipe,df_type,df_partie_consomme,df_famille_gorille,data)\n",
    "except NameError:\n",
    "    print(\"It seems your dataframe has not been created yet. process above scripts first to create your dataframe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "145484ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_downloading_psql(source_checked, user,password,host,port,database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6138150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
